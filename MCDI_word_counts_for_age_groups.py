# -*- coding: utf-8 -*-
"""Plot_occurrence_rate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EkFs7Nf_hgUpbLx3LufwFi706B_HWhX9
"""

import re
import os
import glob
from datetime import datetime, timedelta
from collections import Counter, defaultdict
import pandas as pd

# Define MCDI word lists
action_words = [
    "bite", "blow", "break", "bring", "build", "bump", "buy", "carry", "catch", "chase",
    "clap", "clean", "climb", "close", "cook", "cover", "cry", "cut", "dance", "draw",
    "drink", "drive", "drop", "dry", "dump", "eat", "fall", "feed", "find", "finish",
    "fit", "fix", "get", "give", "go", "have", "hear", "help", "hide", "hit",
    "hold", "hug", "hurry", "jump", "kick", "kiss", "knock", "lick", "like", "listen",
    "look", "love", "make", "open", "paint", "pick", "play", "pour", "pretend", "pull",
    "push", "put", "read", "ride", "rip", "run", "say", "see", "shake", "share",
    "show", "sing", "sit", "skate", "sleep", "slide", "smile", "spill", "splash", "stand",
    "stay", "stop", "sweep", "swim", "swing", "take", "talk", "taste", "tear", "think",
    "throw", "tickle", "touch", "wait", "wake", "walk", "wash", "watch", "wipe", "wish",
    "work", "write"
]

animal_sounds = [
    "baa baa", "meow", "uh oh", "choo choo", "moo", "vroom", "cockadoodledoo", "ouch", "woof woof",
    "grr", "quack quack", "yum yum"
]

animals = [
    "alligator", "animal", "ant", "bear", "bee", "bird", "bug", "bunny", "butterfly", "cat",
    "chicken", "cow", "deer", "dog", "donkey", "duck", "elephant", "fish", "frog", "giraffe",
    "goose", "hen", "horse", "kitty", "lamb", "lion", "monkey", "moose", "mouse", "owl",
    "penguin", "pig", "pony", "puppy", "rooster", "sheep", "squirrel", "teddybear", "tiger",
    "turkey", "turtle", "wolf", "zebra"
]

vehicles = [
    "airplane", "bicycle", "boat", "bus", "car", "firetruck", "helicopter", "motorcycle", "sled",
    "stroller", "tractor", "train", "tricycle", "truck"
]

toys = [
    "ball", "balloon", "bat", "block", "book", "bubbles", "chalk", "crayon", "doll", "game",
    "glue", "pen", "pencil", "play dough", "present", "puzzle", "story", "toy"
]

food_and_drink = [
    "apple", "applesauce", "banana", "beans", "bread", "butter", "cake", "candy", "carrots", "cereal",
    "cheerios", "cheese", "chicken", "chocolate", "coffee", "coke", "cookie", "corn", "cracker", "donut",
    "drink", "egg", "fish", "food", "french fries", "grapes", "green beans", "gum", "hamburger", "ice",
    "ice cream", "jello", "jelly", "juice", "lollipop", "meat", "melon", "milk", "muffin", "noodles",
    "nuts", "orange", "pancake", "peanut butter", "peas", "pickle", "pizza", "popcorn", "popsicle", "potato",
    "potato chip", "pretzel", "pudding", "pumpkin", "raisin", "salt", "sandwich", "sauce", "soda/pop", "soup",
    "spaghetti", "strawberry", "toast", "tuna", "vanilla", "vitamins", "water", "yogurt"
]

clothing = [
    "beads", "belt", "bib", "boots", "button", "coat", "diaper", "dress", "gloves", "hat",
    "jacket", "jeans", "mittens", "necklace", "pajamas", "pants", "scarf", "shirt", "shoe",
    "shorts", "slipper", "sneaker", "snowsuit", "sock", "sweater", "tights", "underpants", "zipper"
]

body_parts = [
    "ankle", "arm", "belly button", "buttocks/bottom", "cheek", "chin", "ear", "eye", "face", "feet",
    "finger", "hair", "hand", "head", "knee", "leg", "lips", "mouth", "nose", "owie/boo boo", "penis",
    "shoulder", "tooth", "toe", "tongue", "tummy", "vagina"
]

small_household_items = [
    "basket", "blanket", "bottle", "box", "bowl", "broom", "brush", "bucket", "camera", "can",
    "clock", "comb", "cup", "dish", "fork", "garbage", "glass", "glasses", "hammer", "jar",
    "keys", "knife", "lamp", "light", "medicine", "money", "mop", "nail", "napkin", "paper",
    "penny", "picture", "pillow", "plate", "plant", "purse", "radio", "scissors", "soap", "spoon",
    "tape", "telephone", "tissue/kleenex", "toothbrush", "towel", "trash", "tray", "vacuum", "walker", "watch"
]

furniture_and_rooms = [
    "basement", "bathroom", "bathtub", "bed", "bedroom", "bench", "chair", "closet", "couch", "crib",
    "door", "drawer", "dryer", "garage", "high chair", "kitchen", "living room", "oven", "play pen",
    "porch", "potty", "refrigerator", "rocking chair", "room", "shower", "sink", "sofa", "stairs", "stove",
    "table", "TV", "washing machine", "window"
]

outside_things = [
    "backyard", "cloud", "flag", "flower", "garden", "grass", "hose", "ladder", "lawn mower", "moon",
    "pool", "rain", "rock", "roof", "sandbox", "shovel", "sidewalk", "sky", "slide", "snow",
    "snowman", "sprinkler", "star", "stick", "stone", "street", "sun", "swing", "tree", "water", "wind"
]

places_to_go = [
    "beach", "camping", "church", "circus", "country", "downtown", "farm", "gas station", "home", "house",
    "movie", "outside", "park", "party", "picnic", "playground", "school", "store", "woods", "work", "yard", "zoo"
]

people = [
    "aunt", "baby", "babysitter", "babysitter's name", "boy", "brother", "child", "child's own name", "clown", "cowboy",
    "daddy", "doctor", "fireman", "friend", "girl", "grandma", "grandpa", "lady", "mailman", "man", "mommy", "nurse",
    "people", "person", "pet's name", "police", "sister", "teacher", "uncle"
]

games_and_routine = [
    "bath", "breakfast", "bye", "call (on phone)", "dinner", "give me five!", "gonna get you!", "go potty", "hello", "hi",
    "lunch", "nap", "night night", "no", "patty cake", "peekaboo", "please", "shopping", "shh/shush/hush", "snack",
    "so big!", "thank you", "this little piggy", "turn around", "yes"
]

# Define a dictionary to map each word to its category
word_categories = {
    "action_words": action_words,
    "animal_sounds": animal_sounds,
    "animals": animals,
    "vehicles": vehicles,
    "toys": toys,
    "food_and_drink": food_and_drink,
    "clothing": clothing,
    "body_parts": body_parts,
    "small_household_items": small_household_items,
    "furniture_and_rooms": furniture_and_rooms,
    "outside_things": outside_things,
    "places_to_go": places_to_go,
    "people": people,
    "games_and_routine": games_and_routine
}
def normalize_word(word):
    return re.sub(r'[^\w\s]', '', word.lower()).strip()
# Reverse mapping of word to category for fast lookup
word_to_category = {}
for category, words in word_categories.items():
    for word in words:
        word_to_category[normalize_word(word)] = category


# Combine all MCDI words into a single list
mcdi_words = (
    action_words + animal_sounds + animals + vehicles + toys + food_and_drink + clothing +
    body_parts + small_household_items + furniture_and_rooms + outside_things + places_to_go +
    people + games_and_routine
)



normalized_mcdi_words = set(normalize_word(word) for word in mcdi_words)

# Function to calculate the month based on the filename
def calculate_month(filename):
    weeks = int(filename[:3])
    months = weeks // 4
    return months

# Function to map a month to its interval group
def get_month_group(month, month_intervals):
    for group, interval in month_intervals.items():
        if month in interval:
            return group
    return None

# Function to parse SRT timestamp
def parse_srt_time(srt_time_str):
    time_format = '%H:%M:%S,%f'
    return datetime.strptime(srt_time_str, time_format)

# Function to tokenize text into words
def tokenize_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text.split()

# Function to calculate WPM and word counts
def calculate_wpm_and_counts(srt_file_path):
    with open(srt_file_path, 'r', encoding='utf-8') as file:
        content = file.read()
    subtitle_blocks = re.findall(
        r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)\n\n', content, re.DOTALL
    )
    total_words = []
    total_duration = timedelta()
    mcdi_word_counts = Counter()
    all_word_counts = Counter()
    total_mcdi_words = []
    category_word_counts = defaultdict(Counter)

    # Create sets to track unique words per category
    category_unique_words = {
        'action_words': set(), 'animal_sounds': set(), 'animals': set(), 'vehicles': set(),
        'toys': set(), 'food_and_drink': set(), 'clothing': set(), 'body_parts': set(),
        'small_household_items': set(), 'furniture_and_rooms': set(), 'outside_things': set(),
        'places_to_go': set(), 'people': set(), 'games_and_routine': set()
    }

    for block in subtitle_blocks:
        start_time = parse_srt_time(block[1])
        end_time = parse_srt_time(block[2])
        dialogue_text = block[3]
        words = tokenize_text(dialogue_text)
        total_words.extend(words)
        for word in words:
            all_word_counts[word] += 1
            if word in normalized_mcdi_words:
                total_mcdi_words.extend(word)
                mcdi_word_counts[word] += 1
                if word in word_to_category:
                    category_word_counts[word_to_category[word]][word] += 1
                # Check which category the word belongs to and add to the respective set
                for category, word_list in zip(
                    ['action_words', 'animal_sounds', 'animals', 'vehicles', 'toys', 'food_and_drink',
                     'clothing', 'body_parts', 'small_household_items', 'furniture_and_rooms',
                     'outside_things', 'places_to_go', 'people', 'games_and_routine'],
                    [action_words, animal_sounds, animals, vehicles, toys, food_and_drink, clothing,
                     body_parts, small_household_items, furniture_and_rooms, outside_things, places_to_go,
                     people, games_and_routine]):

                    if word in set(normalize_word(w) for w in word_list):
                        category_unique_words[category].add(word)
        total_duration += end_time - start_time
    unique_words = set(total_words)
    unique_mcdi_words = set(total_mcdi_words)
    total_minutes = total_duration.total_seconds() / 60
    wpm = len(total_words) / total_minutes if total_minutes > 0 else 0
    return wpm, total_duration, mcdi_word_counts, all_word_counts, unique_words, unique_mcdi_words,category_word_counts,category_unique_words

# Find all .srt files in the directory and subdirectories
def find_srt_files_in_directories(directory_path):
    return glob.glob(os.path.join(directory_path, '**/*.srt'), recursive=True)

# Main execution block
# Main execution
if __name__ == "__main__":
    month_intervals = {
        3: [0, 1, 2, 3],
        6: [4, 5, 6],
        9: [7, 8, 9],
        12: [10, 11, 12],
        18: [13, 14, 15,16,17,18],
        24: [19,20,21,22,23,24],
        30: [25,26,27,28,29,30],
    }



    directory_path = '../transcriptions/'  # Replace with your actual directory path
    output_excel_path = './MCDI_word_counts_for_age_groups.xlsx'  # Output Excel file path

    srt_files = find_srt_files_in_directories(directory_path)

    group_stats = defaultdict(lambda: {
        'total_words': [],
        'total_duration': timedelta(),
        'unique_words': set(),
        'mcdi_word_counts': Counter(),
        'unique_mcdi_words': set(),
        'all_word_counts': Counter(),
        'mcdi_over_total': [],
        'category_word_counts': defaultdict(Counter),
        'category_unique_words': {
            'action_words': set(), 'animal_sounds': set(), 'animals': set(), 'vehicles': set(),
            'toys': set(), 'food_and_drink': set(), 'clothing': set(), 'body_parts': set(),
            'small_household_items': set(), 'furniture_and_rooms': set(), 'outside_things': set(),
            'places_to_go': set(), 'people': set(), 'games_and_routine': set()
        },
    })

    for srt_file_path in srt_files:
        filename = os.path.basename(srt_file_path)
        month = calculate_month(filename)
        group = get_month_group(month, month_intervals)
        if group:
            wpm, total_duration, mcdi_word_counts, all_word_counts,unique_words, unique_mcdi_words,category_word_counts,category_unique_words = calculate_wpm_and_counts(srt_file_path)
            group_stats[group]['total_duration'] += total_duration
            group_stats[group]['mcdi_word_counts'].update(mcdi_word_counts)
            group_stats[group]['all_word_counts'].update(all_word_counts)
            group_stats[group]['unique_words'].update(unique_words)
            group_stats[group]['unique_mcdi_words'].update(unique_mcdi_words)

            for category, words in category_unique_words.items():
                group_stats[group]['category_unique_words'][category].update(words)

            # Update category-specific word counts
            for category, counts in category_word_counts.items():
                group_stats[group]['category_word_counts'][category].update(counts)

    graph_df = pd. DataFrame(columns = ['Group','MCDI over Total','Total MCDI over Unique MCDI'])
    with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:
        for group, stats in group_stats.items():
            mcdi_counts_df = pd.DataFrame(list(stats['mcdi_word_counts'].items()), columns=['Word', 'Count'])
            all_words_df = pd.DataFrame(list(stats['all_word_counts'].items()), columns=['Word', 'Count'])
            mcdi_counts_df['Proportion'] = mcdi_counts_df['Count'] / sum(stats['mcdi_word_counts'].values())
            all_words_df['Proportion'] = all_words_df['Count'] / sum(stats['all_word_counts'].values())

            # Summary data including counts for each word category
            summary_data = {
                'Total Words': [sum(stats['all_word_counts'].values())],
                'Total MCDI Words': [sum(stats['mcdi_word_counts'].values())],
                'Total Unique Words': [len(stats['all_word_counts'].keys())],
                'Total MCDI Unique Words': [len(stats['mcdi_word_counts'].keys())],
                'Total Duration (min)': [stats['total_duration'].total_seconds() / 60],
                'Average Words Per Minute': [sum(stats['all_word_counts'].values()) / (stats['total_duration'].total_seconds() / 60 if stats['total_duration'].total_seconds() > 0 else 1)],
                'MCDI over Total': sum(stats['mcdi_word_counts'].values()) / sum(stats['all_word_counts'].values()),
                'Unique MCDI over Total MCDI': len(stats['mcdi_word_counts'].keys()) / len(stats['all_word_counts'].keys())
            }

            # Add columns for unique word counts in each category
            for category in ['action_words', 'animal_sounds', 'animals', 'vehicles', 'toys', 'food_and_drink',
                             'clothing', 'body_parts', 'small_household_items', 'furniture_and_rooms',
                             'outside_things', 'places_to_go', 'people', 'games_and_routine']:
                summary_data[f'Unique {category}'] = len(stats['category_unique_words'][category])

            # Add category-wise word counts to the summary
            for category, counts in stats['category_word_counts'].items():
                summary_data[f'Total {category} Words'] = [sum(counts.values())]

            summary_df = pd.DataFrame(summary_data)

            print("Age Group: ",group,"\n",summary_df)

            new_row = pd.DataFrame({'Group': [group], 'MCDI over Total': [sum(stats['mcdi_word_counts'].values())/sum(stats['all_word_counts'].values()),], 'Total MCDI over Unique MCDI': [len(stats['mcdi_word_counts'].keys())/len(stats['all_word_counts'].keys())]})

            # Appending the new ro
            graph_df = pd.concat([graph_df, new_row], ignore_index=True)

            #print(f'MCDI OVER MCDI TOTAL for {group} : {sum(stats['mcdi_word_counts'].values())/len(mcdi_words)}')
            summary_df.to_excel(writer, sheet_name=f'{group}_Summary', index=False)
            mcdi_counts_df.to_excel(writer, sheet_name=f'{group}_MCDI_Words', index=False)
            all_words_df.to_excel(writer, sheet_name=f'{group}_All_Words', index=False)

    print(f'All data has been saved to {output_excel_path}.')

